{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bim File\n",
    "\n",
    "variant identifier and minor allele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_bim=pd.read_csv('Data/DataS1.bim', sep='\\t', header=None)\n",
    "# df_bim = 1 and 4 columns\n",
    "df_bim = df_bim[[1, 4]]\n",
    "\n",
    "df_bim.rename(columns={1: 'VariantID', 4: 'minor'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conver df_bim['variantID'] to a list\n",
    "columns= df_bim['VariantID'].to_list()\n",
    "columns.insert(0, 'familyID')\n",
    "columns.insert(1, 'individualID')\n",
    "columns.insert(2, 'fatherID')\n",
    "columns.insert(3, 'motherID')\n",
    "columns.insert(4,'Sex')\n",
    "columns.insert(5, 'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "minor=df_bim['minor'].to_list()\n",
    "minor.insert(0, 'None')\n",
    "minor.insert(1, 'None')\n",
    "minor.insert(2, 'None')\n",
    "minor.insert(3, 'None')\n",
    "minor.insert(4,'None')\n",
    "minor.insert(5, 'None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ped File\n",
    "\n",
    "familly id and individual id and allels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the ped file by familly id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'Data/out/*': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! rm -r Data/out/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "def split_and_convert(file_path):\n",
    "    # Create a directory to store output files\n",
    "    os.makedirs('Data/out', exist_ok=True)\n",
    "    populations = []\n",
    "    with open(file_path, 'r') as ped_file:\n",
    "        for row in ped_file:\n",
    "            row_data = row.strip().split()\n",
    "            populations.append(row_data[0])\n",
    "            pedigree = row_data[0]\n",
    "            with open(f'Data/out/{pedigree}.txt', 'a') as out_file:\n",
    "                # Join the pairs of alleles in each row\n",
    "                new_fields = row_data[:6]\n",
    "                for i in range(6, len(row_data), 2):\n",
    "                    new_fields.append(row_data[i] + row_data[i+1])\n",
    "                # Write the new fields to the output file\n",
    "                out_file.write(' '.join(new_fields) + '\\n')\n",
    "        \n",
    "    return list(set(populations))\n",
    "\n",
    "file_path = 'Data/DataS1.ped'\n",
    "\n",
    "populations = split_and_convert(file_path)\n",
    "print(populations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfeuro = pd.read_excel(\n",
    "    'Data/Eurasian - Dataset_tims.xlsx', sheet_name='Eurasian')\n",
    "dfeuro = pd.DataFrame(dfeuro)\n",
    "dfeuro.rename(columns={\n",
    "              'Date mean in BP in years before 1950 CE [OxCal mu for a direct radiocarbon date, and average of range for a contextual date]': 'date'}, inplace=True)\n",
    "\n",
    "# date_range is a list of the range of dates from 0 to 12000 years ago in 1000 year intervals\n",
    "date_range = list(range(0, 12000, 1000)) \n",
    "# if dfeuro['date'] is in the range of date_range, then dfeuro['cat_date'] is the index of the range\n",
    "dfeuro['cat_date']=pd.cut(dfeuro['date'], date_range, labels=range(0, len(date_range)-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def freq(pop_path, country):\n",
    "    '''This function takes a population file and returns a dictionary of the frequency of each variant'''\n",
    "    df = pd.read_csv(pop_path, sep=' ', header=None)\n",
    "    df.columns = columns\n",
    "    df.date = 0\n",
    "    # print(len(df))\n",
    "    # locate df['individualID'] in dfeuro['Master ID'] and add df['cat_date'] to the df[date]\n",
    "    for i in range(0, len(df)):\n",
    "        for j in range(0, len(dfeuro)):\n",
    "            if df['individualID'][i] == dfeuro['Master ID'][j]:\n",
    "                df['date'][i] = dfeuro['cat_date'][j]\n",
    "  \n",
    "    # get unique dates in df['date'] and store in a list and remove None\n",
    "    date = df['date'].unique()\n",
    "    date = date.tolist()\n",
    "    if 0 in date:\n",
    "        date.remove(0)\n",
    "    \n",
    "\n",
    "    countryfreq = {}\n",
    "    \n",
    "    for d in date:\n",
    "        freqdate= []\n",
    "        df2 = df[df['date'] == d]\n",
    "        for i in range(6, len(df.columns)):\n",
    "            minorAllele = minor[i]\n",
    "            count = 0\n",
    "            total = len(df2)*2\n",
    "            for j in range(0, len(df2)):\n",
    "                # count occurrences of the minor allele in column i\n",
    "                count += str(df2.iloc[j, i]).count(str(minorAllele))\n",
    "            freqdate.append(round(count/total),3)\n",
    "            \n",
    "        name= f'{country}_{d}'\n",
    "        countryfreq[name] = freqdate\n",
    "        \n",
    "    return countryfreq\n",
    "\n",
    "\n",
    "# ! rm Data/DataS1_freq.txt\n",
    "# counter = 0\n",
    "# with open('Data/DataS1_freq.txt', 'a') as f:\n",
    "#     for country in populations:\n",
    "#         print(country)\n",
    "#         pop_path=f'Data/out/{country}.txt'\n",
    "#         freq_results = freq(pop_path, country)\n",
    "#         for key, value in freq_results.items():\n",
    "#             str_values = [str(val) for val in value]  # convert float values to strings\n",
    "#             f.write('%s\\t%s\\n' % (key, '\\t'.join(str_values)))\n",
    "#         counter += 1\n",
    "#         print(counter, 'of', len(populations), 'done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "# Open the input and output files\n",
    "with open('Data/DataS1_freq.txt', 'rb') as f_in, gzip.open('Data/DataS1_freq.txt.gz', 'wb') as f_out:\n",
    "    # Copy the contents of the input file to the output file using gzip compression\n",
    "    f_out.writelines(f_in)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
